#!/bin/bash
set -e

echo "ğŸ¤– Downloading Ollama models for CareerGini..."

# Check if Ollama is running
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âŒ Ollama is not running. Starting Ollama service..."
    sudo docker compose up -d ollama
    echo "â³ Waiting for Ollama to be ready..."
    sleep 15
fi

echo "ğŸ“¥ Downloading Qwen2.5 7B Instruct (Q4_K_M) - Complex reasoning..."
sudo docker compose exec ollama ollama pull qwen2.5:7b-instruct-q4_K_M || ollama pull qwen2.5:7b-instruct-q4_K_M

echo "ğŸ“¥ Downloading Phi3 Mini 3.8B (Q4_K_M) - Fast tasks..."
sudo docker compose exec ollama ollama pull phi3:mini || ollama pull phi3:mini

echo "ğŸ“¥ Downloading Qwen2.5-Coder 7B (Q4_K_M) - Technical analysis..."
sudo docker compose exec ollama ollama pull qwen2.5-coder:7b-instruct-q4_K_M || ollama pull qwen2.5-coder:7b-instruct-q4_K_M

echo "âœ… All models downloaded successfully!"
echo ""
echo "ğŸ“Š Available models:"
sudo docker compose exec ollama ollama list || ollama list

echo ""
echo "ğŸ’¾ Total storage used: ~12 GB"
echo "ğŸ¯ Models ready for inference!"
